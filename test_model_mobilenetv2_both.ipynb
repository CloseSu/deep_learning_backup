{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.layers import Input\n",
    "from tensorflow.python.keras.models import Model, load_model\n",
    "from tensorflow.python.keras.layers import Convolution2D , Cropping2D, SeparableConv2D\n",
    "from tensorflow.python.keras.layers import Dropout, Flatten, Dense, Cropping2D, Lambda, concatenate, BatchNormalization, Activation, GlobalAveragePooling2D\n",
    "from tensorflow.python.keras.callbacks import ModelCheckpoint, EarlyStopping\n",
    "import tensorflow as tf\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "import json\n",
    "import cv2\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model():\n",
    "    img_in = Input(shape=(120, 160,3), name='img_in')  \n",
    "    x =  Cropping2D(cropping=((50, 0), (0, 0)))(img_in)\n",
    "    x = Convolution2D(32, (3, 3), strides=(2, 2), padding='same')(x)\n",
    "    \n",
    "    filte1 = 16\n",
    "    filte2 = 24\n",
    "    filte3 = 32\n",
    "    filte4 = 40\n",
    "    filte5 = 48\n",
    "    \n",
    "    ############################################# 1\n",
    "    x = Convolution2D(filte1, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "        \n",
    "    x = SeparableConv2D(filte1, (3, 3), strides=(2, 2), depth_multiplier=1, padding='same')(x)     \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Convolution2D(filte1, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    ############################################## 2\n",
    "    x = Convolution2D(filte2 * 6, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "        \n",
    "    x = SeparableConv2D(filte2, (3, 3), strides=(2, 2), depth_multiplier=1, padding='same')(x)     \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Convolution2D(filte2, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    ############################################ 3\n",
    "    x = Convolution2D(filte3 * 6, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "        \n",
    "    x = SeparableConv2D(filte3, (3, 3), strides=(2, 2), depth_multiplier=1, padding='same')(x)     \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Convolution2D(filte3, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    ############################################ 4\n",
    "    x = Convolution2D(filte4 * 6, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "        \n",
    "    x = SeparableConv2D(filte4, (3, 3), strides=(2, 2), depth_multiplier=1, padding='same')(x)     \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Convolution2D(filte4, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    ############################################ 5\n",
    "    x = Convolution2D(filte5, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "        \n",
    "    x = SeparableConv2D(filte5, (3, 3), strides=(2, 2), depth_multiplier=1, padding='same')(x)     \n",
    "    x = BatchNormalization()(x)\n",
    "    x = Activation('relu')(x)\n",
    "    \n",
    "    x = Convolution2D(filte5, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    ############################################ end\n",
    "    \n",
    "   \n",
    "    x = Convolution2D(1280, (1, 1), strides=(1, 1), padding='same')(x)\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "   \n",
    "    \n",
    "    x = Dense(100, activation='linear')(x)\n",
    "    x = Dropout(.1)(x)\n",
    "    x = Dense(50, activation='linear')(x)\n",
    "    x = Dropout(.1)(x)  \n",
    "      \n",
    "    angle_out = Dense(1, activation='tanh', name='angle_out')(x)  \n",
    "    throttle_out = Dense(1, activation='sigmoid', name='throttle_out')(x)  \n",
    "    \n",
    "    model = Model(inputs=[img_in], outputs=[angle_out, throttle_out])\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss={'angle_out': 'mean_squared_error',\n",
    "                        'throttle_out': 'mean_squared_error'},\n",
    "                  loss_weights={'angle_out': 0.5, 'throttle_out': 0.5})\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "real_df = pd.read_csv('real_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def select_rgb_white_yellow(image): \n",
    "    # white color mask\n",
    "    lower = np.uint8([0, 0, 0])\n",
    "    upper = np.uint8([100, 100, 100])\n",
    "    white_mask = cv2.inRange(image, lower, upper)\n",
    "    # yellow color mask\n",
    "    lower = np.uint8([0, 0, 0])\n",
    "    upper = np.uint8([50, 50, 50])\n",
    "    yellow_mask = cv2.inRange(image, lower, upper)\n",
    "    # combine the mask\n",
    "    mask = cv2.bitwise_or(white_mask, yellow_mask)\n",
    "    masked = cv2.bitwise_and(image, image, mask = mask)\n",
    "    return masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_data_simu(img):     \n",
    "    img = Image.open(img)\n",
    "    for i in range(img.size[0]):    \n",
    "        for j in range(img.size[1]):\n",
    "            if j > 50:\n",
    "                r,g,b = img.getpixel((i,j))\n",
    "                if(r > 190 and g > 200 and b > 220):\n",
    "                     img.putpixel((i,j), (34,37,23))\n",
    "                elif(r > 200 and g > 190 and b < 180 and b > 120):  \n",
    "                     img.putpixel((i,j), (52,33,30))\n",
    "   \n",
    "    img = select_rgb_white_yellow(np.array(img))    \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_data_simu_canny(img):     \n",
    "    img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "    img = cv2.Canny(img,50,300)\n",
    "    img = np.stack((img,img,img), axis=2)   \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_data_real(img):     \n",
    "    img = Image.open(img)    \n",
    "    img = select_rgb_white_yellow(np.array(img))               \n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_transfer_data_real_canny(img):\n",
    "    loc = img\n",
    "    try:\n",
    "        img = cv2.imread(img, cv2.IMREAD_GRAYSCALE)\n",
    "        img = cv2.Canny(img,100,400)\n",
    "        img = np.stack((img,img,img), axis=2)\n",
    "        return img\n",
    "    except:\n",
    "        print('error: '+ loc)\n",
    "        img = 'error'\n",
    "        return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6293, 7)\n",
      "(6293, 7)\n",
      "00:00:30\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/pandas/core/ops.py:1122: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  result = libops.scalar_compare(x, y, op)\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "real_df[\"img\"] = real_df[\"cam/image_array\"].apply(lambda x: get_transfer_data_real_canny(x))\n",
    "print(real_df.shape)\n",
    "real_df = real_df[real_df['img'] != 'error']\n",
    "real_df.head()\n",
    "print(real_df.shape)\n",
    "\n",
    "elapsed_time = time.time() - start_time\n",
    "peroid = time.strftime(\"%H:%M:%S\", time.gmtime(elapsed_time))\n",
    "print(peroid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_img_list(df):\n",
    "    img_list = []\n",
    "    for i in df[\"img\"].values:\n",
    "        img_list.append(i)  \n",
    "    return np.array(img_list)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(df, model, name):\n",
    "    early_stop = EarlyStopping(monitor='val_loss',\n",
    "                                   min_delta=.0005,\n",
    "                                   patience=5,\n",
    "                                   verbose=2,\n",
    "                                   mode='auto')\n",
    "    save_best = ModelCheckpoint(name+'_model',\n",
    "                                    monitor='val_loss',\n",
    "                                    verbose=2,\n",
    "                                    save_best_only=True,\n",
    "                                    mode='min')\n",
    "    model.fit(x=get_img_list(df),\n",
    "                 y=[df[\"user/angle\"].values,df[\"user/throttle\"].values],\n",
    "                 batch_size=32,\n",
    "                 epochs=100,\n",
    "                 verbose=1,\n",
    "                 callbacks=[early_stop,save_best],             \n",
    "                 validation_split=0.1\n",
    "                )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_speed_models(df, range_list, name):\n",
    "    for throttle in range_list:\n",
    "        new_model = test_model()\n",
    "        df[\"user/throttle\"] = throttle\n",
    "        train_model(df,new_model, name + str(throttle))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# real_df['user/angle'][real_df['user/angle'] > 0.5] = 0.7\n",
    "# real_df['user/angle'][real_df['user/angle'] < -0.5] = -0.7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build_speed_models(real_df,[0.8], 'real_angle2_throttle_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_speed_models_transfer(df, model, range_list, name):\n",
    "    for throttle in range_list:       \n",
    "        df[\"user/throttle\"] = throttle\n",
    "        train_model(df,model, name + str(throttle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 5663 samples, validate on 630 samples\n",
      "Epoch 1/100\n",
      "5663/5663 [==============================] - 50s 9ms/step - loss: 0.0459 - angle_out_loss: 0.0843 - throttle_out_loss: 0.0074 - val_loss: 0.0347 - val_angle_out_loss: 0.0694 - val_throttle_out_loss: 5.7084e-05\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03473, saving model to transfer_20181025_light_0.9_model\n",
      "Epoch 2/100\n",
      "5663/5663 [==============================] - 48s 8ms/step - loss: 0.0326 - angle_out_loss: 0.0644 - throttle_out_loss: 7.5454e-04 - val_loss: 0.0286 - val_angle_out_loss: 0.0568 - val_throttle_out_loss: 3.1661e-04\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03473 to 0.02858, saving model to transfer_20181025_light_0.9_model\n",
      "Epoch 3/100\n",
      "5663/5663 [==============================] - 49s 9ms/step - loss: 0.0294 - angle_out_loss: 0.0584 - throttle_out_loss: 4.4148e-04 - val_loss: 0.0322 - val_angle_out_loss: 0.0640 - val_throttle_out_loss: 4.0356e-04\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "5663/5663 [==============================] - 48s 8ms/step - loss: 0.0283 - angle_out_loss: 0.0562 - throttle_out_loss: 3.7508e-04 - val_loss: 0.0295 - val_angle_out_loss: 0.0590 - val_throttle_out_loss: 1.2819e-04\n",
      "\n",
      "Epoch 00004: val_loss did not improve\n",
      "Epoch 5/100\n",
      "5663/5663 [==============================] - 46s 8ms/step - loss: 0.0268 - angle_out_loss: 0.0534 - throttle_out_loss: 3.1110e-04 - val_loss: 0.0310 - val_angle_out_loss: 0.0618 - val_throttle_out_loss: 8.9822e-05\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "5663/5663 [==============================] - 48s 8ms/step - loss: 0.0252 - angle_out_loss: 0.0500 - throttle_out_loss: 3.2829e-04 - val_loss: 0.0315 - val_angle_out_loss: 0.0625 - val_throttle_out_loss: 3.8529e-04\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "5663/5663 [==============================] - 47s 8ms/step - loss: 0.0240 - angle_out_loss: 0.0473 - throttle_out_loss: 6.7070e-04 - val_loss: 0.0291 - val_angle_out_loss: 0.0577 - val_throttle_out_loss: 5.7194e-04\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 00007: early stopping\n",
      "Train on 5663 samples, validate on 630 samples\n",
      "Epoch 1/100\n",
      "5663/5663 [==============================] - 45s 8ms/step - loss: 0.0238 - angle_out_loss: 0.0470 - throttle_out_loss: 6.5760e-04 - val_loss: 0.0342 - val_angle_out_loss: 0.0681 - val_throttle_out_loss: 2.7084e-04\n",
      "\n",
      "Epoch 00001: val_loss improved from inf to 0.03420, saving model to transfer_20181025_light_1.0_model\n",
      "Epoch 2/100\n",
      "5663/5663 [==============================] - 43s 8ms/step - loss: 0.0237 - angle_out_loss: 0.0471 - throttle_out_loss: 2.0454e-04 - val_loss: 0.0342 - val_angle_out_loss: 0.0682 - val_throttle_out_loss: 9.4480e-05\n",
      "\n",
      "Epoch 00002: val_loss improved from 0.03420 to 0.03416, saving model to transfer_20181025_light_1.0_model\n",
      "Epoch 3/100\n",
      "5663/5663 [==============================] - 48s 9ms/step - loss: 0.0215 - angle_out_loss: 0.0429 - throttle_out_loss: 1.3121e-04 - val_loss: 0.0371 - val_angle_out_loss: 0.0740 - val_throttle_out_loss: 9.9547e-05\n",
      "\n",
      "Epoch 00003: val_loss did not improve\n",
      "Epoch 4/100\n",
      "5663/5663 [==============================] - 49s 9ms/step - loss: 0.0203 - angle_out_loss: 0.0405 - throttle_out_loss: 1.5782e-04 - val_loss: 0.0326 - val_angle_out_loss: 0.0650 - val_throttle_out_loss: 1.3086e-04\n",
      "\n",
      "Epoch 00004: val_loss improved from 0.03416 to 0.03257, saving model to transfer_20181025_light_1.0_model\n",
      "Epoch 5/100\n",
      "5663/5663 [==============================] - 49s 9ms/step - loss: 0.0200 - angle_out_loss: 0.0398 - throttle_out_loss: 1.2514e-04 - val_loss: 0.0377 - val_angle_out_loss: 0.0753 - val_throttle_out_loss: 6.7168e-05\n",
      "\n",
      "Epoch 00005: val_loss did not improve\n",
      "Epoch 6/100\n",
      "5663/5663 [==============================] - 48s 8ms/step - loss: 0.0188 - angle_out_loss: 0.0376 - throttle_out_loss: 8.4322e-05 - val_loss: 0.0344 - val_angle_out_loss: 0.0689 - val_throttle_out_loss: 4.4472e-05\n",
      "\n",
      "Epoch 00006: val_loss did not improve\n",
      "Epoch 7/100\n",
      "5663/5663 [==============================] - 48s 8ms/step - loss: 0.0175 - angle_out_loss: 0.0349 - throttle_out_loss: 7.7014e-05 - val_loss: 0.0365 - val_angle_out_loss: 0.0730 - val_throttle_out_loss: 3.3226e-05\n",
      "\n",
      "Epoch 00007: val_loss did not improve\n",
      "Epoch 8/100\n",
      "5663/5663 [==============================] - 48s 8ms/step - loss: 0.0168 - angle_out_loss: 0.0335 - throttle_out_loss: 5.1399e-05 - val_loss: 0.0379 - val_angle_out_loss: 0.0758 - val_throttle_out_loss: 3.6648e-05\n",
      "\n",
      "Epoch 00008: val_loss did not improve\n",
      "Epoch 9/100\n",
      "5663/5663 [==============================] - 48s 8ms/step - loss: 0.0170 - angle_out_loss: 0.0340 - throttle_out_loss: 7.4166e-05 - val_loss: 0.0359 - val_angle_out_loss: 0.0717 - val_throttle_out_loss: 5.0200e-05\n",
      "\n",
      "Epoch 00009: val_loss did not improve\n",
      "Epoch 00009: early stopping\n"
     ]
    }
   ],
   "source": [
    "build_speed_models_transfer(real_df,  load_model('old_mix_data/mix_model_model'), [0.9,1.0], 'transfer_20181025_light_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
